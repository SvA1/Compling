{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+JUdGhdDj+sUfTx+r/87o"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybKZOx0F_aIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install Cython numpy\n",
        "!pip install git+https://github.com/lopuhin/python-adagram.git\n",
        "!pip install pymorphy2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1UsVGT6-Dj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import adagram\n",
        "from lxml import html\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "\n",
        "import json, os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4dQ9xEE_cUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "morph = MorphAnalyzer()\n",
        "stops = set(stopwords.words('russian'))\n",
        "punct = punctuation+'«»—…“”*№–'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTi_PTcSCSYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    words = [word.strip(punct) for word in text.lower().split() if word and word not in stops]\n",
        "    words = [word for word in words if word]\n",
        "\n",
        "    return words\n",
        "\n",
        "def normalize(text):\n",
        "    words = tokenize(text)\n",
        "    words = [morph.parse(word)[0].normal_form for word in words if word]\n",
        "\n",
        "    return words\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSq6Znl3M6TS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/corpus_ng.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N3BvxPCOZMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = open('corpus_ng.txt').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu_x9JzDOx3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = normalize(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGwaq-vWNpbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('corpus.txt', 'w')\n",
        "f.write(' '.join(corpus))\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26x464OtM6Ak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!adagram-train corpus.txt out.pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XjYKAhrMnTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vm = adagram.VectorModel.load(\"out.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku8N1jrJD2iF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_xml = html.fromstring(open(\"paraphrases.xml\", 'rb').read())\n",
        "texts_1 = []\n",
        "texts_2 = []\n",
        "classes = []\n",
        "\n",
        "for p in corpus_xml.xpath('//paraphrase'):\n",
        "    texts_1.append(p.xpath('./value[@name=\"text_1\"]/text()')[0])\n",
        "    texts_2.append(p.xpath('./value[@name=\"text_2\"]/text()')[0])\n",
        "    classes.append(p.xpath('./value[@name=\"class\"]/text()')[0])\n",
        "    \n",
        "data = pd.DataFrame({'text_1':texts_1, 'text_2':texts_2, 'label':classes})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74a54A9gEK6g",
        "colab_type": "code",
        "outputId": "582e960f-5ac9-45c0-bb97-e8d38ec5941c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_1</th>\n",
              "      <th>text_2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Полицейским разрешат стрелять на поражение по ...</td>\n",
              "      <td>Полиции могут разрешить стрелять по хулиганам ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Право полицейских на проникновение в жилище ре...</td>\n",
              "      <td>Правила внесудебного проникновения полицейских...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Президент Египта ввел чрезвычайное положение в...</td>\n",
              "      <td>Власти Египта угрожают ввести в стране чрезвыч...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Вернувшихся из Сирии россиян волнует вопрос тр...</td>\n",
              "      <td>Самолеты МЧС вывезут россиян из разрушенной Си...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>В Москву из Сирии вернулись 2 самолета МЧС с р...</td>\n",
              "      <td>Самолеты МЧС вывезут россиян из разрушенной Си...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7222</th>\n",
              "      <td>Путин освободил от должности ряд генералов</td>\n",
              "      <td>Путин снял с должностей более 20 руководителей...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7223</th>\n",
              "      <td>Облака над Москвой в День Победы разгонят девя...</td>\n",
              "      <td>Путеводитель по Дню Победы: как провести 9 мая...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7224</th>\n",
              "      <td>Любляна отпразднует День Победы вместе с Москвой</td>\n",
              "      <td>В Москве ограничат движение в связи с Днем Победы</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7225</th>\n",
              "      <td>Девять самолетов ВВС разгонят облака над Москв...</td>\n",
              "      <td>В Москве ограничат движение в связи с Днем Победы</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7226</th>\n",
              "      <td>9 мая метрополитен Петербурга будет работать к...</td>\n",
              "      <td>Мартынов: комендантский час в Донецке 9 мая бу...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7227 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text_1  ... label\n",
              "0     Полицейским разрешат стрелять на поражение по ...  ...     0\n",
              "1     Право полицейских на проникновение в жилище ре...  ...     0\n",
              "2     Президент Египта ввел чрезвычайное положение в...  ...     0\n",
              "3     Вернувшихся из Сирии россиян волнует вопрос тр...  ...    -1\n",
              "4     В Москву из Сирии вернулись 2 самолета МЧС с р...  ...     0\n",
              "...                                                 ...  ...   ...\n",
              "7222         Путин освободил от должности ряд генералов  ...     0\n",
              "7223  Облака над Москвой в День Победы разгонят девя...  ...    -1\n",
              "7224   Любляна отпразднует День Победы вместе с Москвой  ...    -1\n",
              "7225  Девять самолетов ВВС разгонят облака над Москв...  ...    -1\n",
              "7226  9 мая метрополитен Петербурга будет работать к...  ...    -1\n",
              "\n",
              "[7227 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-fZ0-aVENcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['text_1_norm'] = data['text_1'].apply(normalize)\n",
        "data['text_2_norm'] = data['text_2'].apply(normalize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkYvDe2yExtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = [0,1,2,3,4,5,6,7,8,9]\n",
        "\n",
        "def get_words_in_context(words, window=3):\n",
        "    words_in_context = []\n",
        "\n",
        "    for i in range(len(words)):\n",
        "        word = words[i]\n",
        "        left = words[max(0, i - window):i]\n",
        "        right = words[i + 1:min(len(words), i + window + 1)]\n",
        "        context = left + right\n",
        "        words_in_context.append([word, context])\n",
        "\n",
        "    return words_in_context\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3_yD4X-LY8m",
        "colab_type": "code",
        "outputId": "7c8a2b4f-fe49-4349-e989-c22c3f238f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "get_words_in_context(words)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, [1, 2, 3]],\n",
              " [1, [0, 2, 3, 4]],\n",
              " [2, [0, 1, 3, 4, 5]],\n",
              " [3, [0, 1, 2, 4, 5, 6]],\n",
              " [4, [1, 2, 3, 5, 6, 7]],\n",
              " [5, [2, 3, 4, 6, 7, 8]],\n",
              " [6, [3, 4, 5, 7, 8, 9]],\n",
              " [7, [4, 5, 6, 8, 9]],\n",
              " [8, [5, 6, 7, 9]],\n",
              " [9, [6, 7, 8]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6m-X1vnR8Qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sense_vec(word, context, model):\n",
        "    sense = model.disambiguate(word, context).argmax()\n",
        "    sense_vec = model.sense_vector(word, sense)\n",
        "    return sense_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chx5VPLXLen7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embedding_adagram(text, model, window= 3, dim=100):\n",
        "    \n",
        "    word2context = get_words_in_context(text, window)\n",
        "    \n",
        "    \n",
        "    vectors = np.zeros((len(word2context), dim))\n",
        "    \n",
        "    for i, (word, context) in enumerate(word2context):\n",
        "        \n",
        "        try:\n",
        "            v = sense_vec(word, context, model)\n",
        "            vectors[i] = v\n",
        "        \n",
        "        except (KeyError, ValueError):\n",
        "            continue\n",
        "    \n",
        "    if vectors.any():\n",
        "        vector = np.average(vectors, axis=0)\n",
        "    else:\n",
        "        vector = np.zeros((dim))\n",
        "    \n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vFQfmX3UJww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0--FEW5RxqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_text_1 = [get_embedding_adagram(text, vm) for text in data['text_1_norm']]\n",
        "X_text_2 = [get_embedding_adagram(text, vm) for text in data['text_2_norm']]\n",
        "\n",
        "X_text = np.concatenate([X_text_1, X_text_2], axis=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWd62xLXUJSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = svm.SVC(kernel='linear', C=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBvpmnMxUWVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = data.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vywrmaWUWzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = svm.SVC(kernel='linear', C=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIHEESemUYgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = cross_val_score(clf, X_text, y, cv=5, scoring='f1_macro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1jcUrFUVhTY",
        "colab_type": "code",
        "outputId": "222e28f8-651e-4052-faa9-b4c8132a434e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "scores"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.31782897, 0.34394189, 0.35456698, 0.29280354, 0.30169771])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfd-Zoj-V8Vh",
        "colab_type": "code",
        "outputId": "329baf5e-0852-4c3f-a75b-c70e07f2c9fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "scores.mean()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3221678174827987"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrEltyXNWHAS",
        "colab_type": "text"
      },
      "source": [
        "## Задание 2. Реализовать алгоритм Леска и проверить его на реальном датасете"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am28nnU6UaHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7q1-RSGWjfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lesk(word, sentence):\n",
        "    bestsense = 0\n",
        "    maxoverlap = 0\n",
        "    synsets = [wn.synsets(word)[i].definition() for i in range(len(wn.synsets(word)))]\n",
        "\n",
        "    if type(sentence) is str:\n",
        "        tokens = [token.strip() for token in sentence.split()]\n",
        "    elif type(sentence) is list:\n",
        "        tokens = sentence\n",
        "    \n",
        "    for i, syns in enumerate(synsets):\n",
        "        n=0\n",
        "        syns_tokens = syns.split()\n",
        "        for token in tokens:\n",
        "            if token in syns_tokens:\n",
        "                n +=1\n",
        "        if n > maxoverlap:\n",
        "            bestsense = i\n",
        "            maxoverlap = n\n",
        "    return bestsense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfExoVc7Zzxa",
        "colab_type": "code",
        "outputId": "78d3528d-407c-4a9e-a585-c43c552279fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lesk('day', 'some point or period in time'.split())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz0jmV81Z0Z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_wsd = []\n",
        "corpus = open('corpus_wsd_50k.txt').read().split('\\n\\n')\n",
        "for sent in corpus:\n",
        "    corpus_wsd.append([s.split('\\t') for s in sent.split('\\n')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "208E_rXht3Mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_wsd[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVdW493jclKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_short = corpus_wsd[:1000]\n",
        "wordnet_list = [] \n",
        "lesk_list = [] \n",
        "\n",
        "for i, sent in enumerate(corpus_short):\n",
        "    if sent[0][0]:\n",
        "      context = []\n",
        "\n",
        "      for w in sent:\n",
        "        if '%' in w[0]:\n",
        "          context.append(w[1])\n",
        "          wn_var = wn.lemma_from_key(w[0]).synset()\n",
        "          wordnet_list.append(wn_var)\n",
        "      \n",
        "      words_in_context = get_words_in_context(context)\n",
        "      \n",
        "      for st in words_in_context:\n",
        "        i = lesk(st[0], st[1])\n",
        "        lesk_var = wn.synsets(st[0])[i]\n",
        "        lesk_list.append(lesk_var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBcXmqSrcuyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lists = {'wordnet': wordnet_list, 'lesk': lesk_list}\n",
        "df = pd.DataFrame(data=lists)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbdJuK_3cyJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "match = np.zeros(df.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eyj1afYhYuZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, syn in enumerate(df['wordnet'].values):\n",
        "  if df['lesk'][i] == syn:\n",
        "    match[i] = 1\n",
        "  else:\n",
        "    match[i] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51xlkh94Yw9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "8164d6ed-2424-431b-8070-9af822d19902"
      },
      "source": [
        "df['match'] = match\n",
        "df.head(15)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wordnet</th>\n",
              "      <th>lesk</th>\n",
              "      <th>match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Synset('be.v.01')</td>\n",
              "      <td>Synset('beryllium.n.01')</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Synset('bigger.s.01')</td>\n",
              "      <td>Synset('bigger.s.01')</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Synset('fancy.a.01')</td>\n",
              "      <td>Synset('fancy.n.02')</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Synset('truly.r.01')</td>\n",
              "      <td>Synset('truly.r.01')</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Synset('want.v.02')</td>\n",
              "      <td>Synset('need.n.01')</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Synset('exist.v.01')</td>\n",
              "      <td>Synset('beryllium.n.01')</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Synset('other.a.01')</td>\n",
              "      <td>Synset('other.a.01')</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Synset('cheap.a.01')</td>\n",
              "      <td>Synset('cheap.a.01')</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Synset('communication.n.01')</td>\n",
              "      <td>Synset('communication.n.01')</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Synset('technique.n.01')</td>\n",
              "      <td>Synset('technique.n.01')</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Synset('substitute.v.01')</td>\n",
              "      <td>Synset('substitute.n.01')</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Synset('consider.v.04')</td>\n",
              "      <td>Synset('see.v.05')</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Synset('afford.v.01')</td>\n",
              "      <td>Synset('afford.v.01')</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Synset('spend.v.02')</td>\n",
              "      <td>Synset('spend.v.01')</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Synset('goal.n.01')</td>\n",
              "      <td>Synset('goal.n.01')</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         wordnet                          lesk  match\n",
              "0              Synset('be.v.01')      Synset('beryllium.n.01')    0.0\n",
              "1          Synset('bigger.s.01')         Synset('bigger.s.01')    1.0\n",
              "2           Synset('fancy.a.01')          Synset('fancy.n.02')    0.0\n",
              "3           Synset('truly.r.01')          Synset('truly.r.01')    1.0\n",
              "4            Synset('want.v.02')           Synset('need.n.01')    0.0\n",
              "5           Synset('exist.v.01')      Synset('beryllium.n.01')    0.0\n",
              "6           Synset('other.a.01')          Synset('other.a.01')    1.0\n",
              "7           Synset('cheap.a.01')          Synset('cheap.a.01')    1.0\n",
              "8   Synset('communication.n.01')  Synset('communication.n.01')    1.0\n",
              "9       Synset('technique.n.01')      Synset('technique.n.01')    1.0\n",
              "10     Synset('substitute.v.01')     Synset('substitute.n.01')    0.0\n",
              "11       Synset('consider.v.04')            Synset('see.v.05')    0.0\n",
              "12         Synset('afford.v.01')         Synset('afford.v.01')    1.0\n",
              "13          Synset('spend.v.02')          Synset('spend.v.01')    0.0\n",
              "14           Synset('goal.n.01')           Synset('goal.n.01')    1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEUwIquJY09s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "succeed = df[df['match'] == 1].shape[0]\n",
        "allv = df['match'].shape[0]\n",
        "accuracy = succeed / allv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALCJL7t0Y9R0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "995b3821-473c-4376-fb7d-5808d3a1cf43"
      },
      "source": [
        "accuracy"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5414615675880349"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSghyEKunc_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}